{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb2603f",
   "metadata": {},
   "source": [
    "## Representation Learning using Deep InfoMAX "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3235a68",
   "metadata": {},
   "source": [
    "In this notebook we are going to implement the Deep InfoMAX paper by Hjelm et. al.\n",
    "\n",
    "We are going to implement the algorithm based on the publicly available Chinese Fine Art dataset. You can collect the dataset from this link: https://www.kaggle.com/rickyjli/chinese-fine-art.\n",
    "\n",
    "So, let's get started by importing the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the necessary packages ##\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import alexnet\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f79943",
   "metadata": {},
   "source": [
    "Okay done!\n",
    "\n",
    "We are all set with the packages. Now let's get going with our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting transformations ##\n",
    "\n",
    "aug = transforms.Compose([\n",
    "    transforms.Resize((256 , 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "## Creating our dataset ##\n",
    "\n",
    "class ArtDataset(Dataset):\n",
    "    \n",
    "    def __init__(self , augment = aug , root = 'Images'):\n",
    "        self.root = root\n",
    "        self.images = os.listdir(root)\n",
    "        self.augment = augment\n",
    "        self.length = len(self.images)\n",
    "        \n",
    "    def __getitem__(self , index):\n",
    "        idx = index % self.length\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.root , img_name)\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = aug(img_pil)\n",
    "        \n",
    "        fake_idx = random.choice([ele for ele in range(self.length) if ele != idx])\n",
    "        fake_name = self.images[fake_idx]\n",
    "        fake_path = os.path.join(self.root , fake_name)\n",
    "        fake_pil = Image.open(fake_path).convert('RGB')\n",
    "        fake_tensor = aug(fake_pil)\n",
    "        \n",
    "        return img_tensor , fake_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.length\n",
    "    \n",
    "## Creating our dataset object ##\n",
    "\n",
    "art_dataset = ArtDataset()\n",
    "\n",
    "\n",
    "## Sanity checking our dataset ##\n",
    "\n",
    "random_idx = int(np.random.randint(low = 0 , high = len(art_dataset) , size = 1))\n",
    "\n",
    "real , fake = art_dataset[random_idx]\n",
    "\n",
    "plt.imshow(real.permute(1, 2 , 0))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(fake.permute(1 , 2 , 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb50e0",
   "metadata": {},
   "source": [
    "Now we need to set up our dataloader, which will feed in batches of data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting our dataloader ##\n",
    "\n",
    "art_dataloader = DataLoader(dataset = art_dataset , \n",
    "                            batch_size = 4 , \n",
    "                            shuffle = True)\n",
    "\n",
    "\n",
    "## Setting a visualization utility function ##\n",
    "\n",
    "def show_img(real , fake):\n",
    "    \n",
    "    fig , ax = plt.subplots(figsize = (2 , 2))\n",
    "    plt.imshow(make_grid(real.detach().to('cpu') , 2).permute(1 , 2 , 0))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    plt.title('Real Images')\n",
    "    plt.show()\n",
    "    \n",
    "    fig , ax = plt.subplots(figsize = (2 , 2))\n",
    "    plt.imshow(make_grid(fake.detach().to('cpu') , 2).permute(1 , 2 , 0))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    plt.title('Fake Images')\n",
    "    plt.show()\n",
    "    \n",
    "## Sanity checking ##\n",
    "\n",
    "for real , fake in art_dataloader:\n",
    "    \n",
    "    show_img(real , fake)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1290cfde",
   "metadata": {},
   "source": [
    "Now we must put all our dataloader images into our GPU to promote parallel computing. So the next part is all about transferring the data to the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU Transfer utility functions ##\n",
    "\n",
    "## Checking if cuda is available and setting default device as cuda ##\n",
    "\n",
    "def get_device():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "## Setting the default device ##\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "## Transferring data to a specific device ##\n",
    "\n",
    "def transfer_data(data, device):\n",
    "    \n",
    "    if isinstance(data , (list , tuple)):\n",
    "        return [transfer_data(each_data , device) for each_data in data]\n",
    "    return data.to(device)\n",
    "\n",
    "## Setting the GPU Dataloader ##\n",
    "\n",
    "class GPUDataloader:\n",
    "    \n",
    "    def __init__(self , dl , device):\n",
    "        \n",
    "        self.dl = dl\n",
    "        self.device  = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "        for batch in self.dl:\n",
    "            \n",
    "            yield transfer_data(batch , self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.dl)\n",
    "    \n",
    "## Making our GPU Dataloader object ##\n",
    "\n",
    "art_dl = GPUDataloader(art_dataloader , device)\n",
    "\n",
    "## Visualizing a mini-batch ##\n",
    "\n",
    "for real , fake in art_dl:\n",
    "    \n",
    "    show_img(real , fake)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e9bd7",
   "metadata": {},
   "source": [
    "Now we are going to **build our model**.\n",
    "\n",
    "Our model consists of 3 basic parts: a global feature map extractor, a local feature map extractor (which is the extension of the global feature map) and a discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets first build the global feature extractor ##\n",
    "\n",
    "## It is the output from the last conv layer ##\n",
    "\n",
    "class Global_DIM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.global_encoder = alexnet(pretrained = False).features[:11]\n",
    "        self.flat = nn.Flatten()\n",
    "        self.extended_encoder = nn.Sequential(nn.Linear(57600 , 4096),\n",
    "                                              nn.ReLU(),\n",
    "                                              nn.Linear(4096 , 4096),\n",
    "                                              nn.ReLU(),\n",
    "                                              nn.Linear(4096 , 64))\n",
    "        self.mutual_info = nn.Sequential(nn.Linear(57664 , 512) , \n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(512 , 512) ,\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(512 , 1))\n",
    "        \n",
    "    def forward(self , image):\n",
    "        \n",
    "        global_encode = self.global_encoder(image)\n",
    "        flatten_global_encode = self.flat(global_encode)\n",
    "        extended_encode = self.extended_encoder(flatten_global_encode)\n",
    "        final_out = self.mutual_info(torch.cat([flatten_global_encode , extended_encode] , 1))\n",
    "        \n",
    "        return final_out , global_encode , extended_encode\n",
    "    \n",
    "    \n",
    "## Now lets build the local feature extractor ##\n",
    "\n",
    "class Local_DIM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels = 320 , out_channels = 512 , kernel_size = (1 , 1) , bias = True),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(in_channels = 512 , out_channels = 512 , kernel_size = (1 , 1) , bias = True),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(in_channels = 512 , out_channels = 1 , kernel_size = (1 , 1) , bias = True))\n",
    "        \n",
    "    def forward(self , x):\n",
    "        out = self.conv(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "## Now our Deep InfoMAX model ##\n",
    "\n",
    "class DeepInfomax(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.global_dim = Global_DIM()\n",
    "        self.local_dim = Local_DIM()\n",
    "        \n",
    "    def forward(self , img):\n",
    "        \n",
    "        global_out , global_encode , extended_encode = self.global_dim(img)\n",
    "        \n",
    "        #print(global_encode.shape)\n",
    "        #print(extended_encode.shape)\n",
    "        \n",
    "        local_out = self.local_dim(torch.cat([global_encode , extended_encode.unsqueeze(2).unsqueeze(3).repeat(1 , 1 , \n",
    "                                                                                              global_encode.shape[2] , \n",
    "                                                                                              global_encode.shape[3])] , 1))\n",
    "        return global_out , local_out\n",
    "    \n",
    "\n",
    "## Creating our model ##\n",
    "\n",
    "model = DeepInfomax().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9130b8c",
   "metadata": {},
   "source": [
    "Now lets set our loss functions and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLobal Loss functions ##\n",
    "\n",
    "def global_loss(tensor1 , tensor2):\n",
    "    \n",
    "    loss = -torch.mean((tensor1 - torch.mean(torch.log(torch.sum(torch.exp(tensor2))))))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "## Local Loss function ##\n",
    "\n",
    "def local_loss(tensor1 , tensor2):\n",
    "    \n",
    "    loss = -(1 / (tensor1.shape[2] * tensor1.shape[3])) * torch.mean(\n",
    "        (tensor1 - torch.mean(torch.log(torch.sum(torch.exp(tensor2))))))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "## Setting optimizer ##\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters() , lr = 3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d0921",
   "metadata": {},
   "source": [
    "Now let's train our network!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training our model ##\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "loop = tqdm(art_dl)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for real , fake in loop:\n",
    "        \n",
    "        real_global_out , real_local_out = model(real)\n",
    "        \n",
    "        fake_global_out , fake_local_out = model(fake)\n",
    "        \n",
    "        glob_loss = global_loss(real_global_out , fake_global_out)\n",
    "        \n",
    "        loc_loss = local_loss(real_local_out , fake_local_out)\n",
    "        \n",
    "        total_loss = glob_loss + loc_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        loop.set_description('Epochs : {} / {}'.format(epoch + 1 , num_epochs))\n",
    "        loop.set_postfix(loss = total_loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
