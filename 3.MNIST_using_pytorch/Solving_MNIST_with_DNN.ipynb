{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to utilize GPU for solving the MNIST Dataset which is available as one of the Torchvision datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing the packages\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the dataset and since the dataset consist of images we are going to transform them into flattened tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = MNIST(root = '/data' , \n",
    "                   train = True,\n",
    "                   transform = transforms.ToTensor(),\n",
    "                   download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And done!\n",
    "\n",
    "Now lets check what inside it, by picking one of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "img , label = mnist_data[0]\n",
    "\n",
    "print(img.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep! As expected! The famous MNIST Dataset is loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the number of images it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize one of the randomly picked sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is :  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(33)\n",
    "idx = int(np.random.choice(len(mnist_data) , 1))  ##picks one random number from 60,000\n",
    "\n",
    "img , label = mnist_data[idx]\n",
    "\n",
    "## Visualization ##\n",
    "## Matplotlib expects the datachannel in the last axis and not in the first one ##\n",
    "img = img.reshape(img.shape[1] , img.shape[2]) ##reshaping the image into 28 * 28\n",
    "\n",
    "plt.imshow(img , cmap = 'gray')\n",
    "print('Label is : ' , label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, cool as a whistle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what?\n",
    "\n",
    "Well I love fixing our model, then moving ahead. So in this notebook we are going to implement a 2 layered model with the first hidden layer getting an activation function to impose non-linearity!\n",
    "\n",
    "Now why do we need non-linearity? Well if we simply put linear models, the entire model would make similar thiongs as that of a Linear Regression. Now, think about it, does the pixels of an image have linear relationship with the output target? No, right? Thats why we integrate non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, lets set our model and we will make it a bit generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_model(nn.Module):\n",
    "    def __init__(self , input_size , hidden_size , output_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size , hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size , output_size)\n",
    "        \n",
    "    def forward(self , xb):\n",
    "        xb = xb.reshape(xb.size(0) , -1)\n",
    "        out = self.linear1(xb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "model = mnist_model(784 , 32 , 10)  ##setting an instance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up our loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function ##\n",
    "loss_function = F.cross_entropy\n",
    "\n",
    "## Optimizer ##\n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = 1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Now lets split up our data by shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_index(dataset_size , split_percent):\n",
    "    split_size = int(dataset_size * split_percent)\n",
    "    random_idx = np.random.permutation(dataset_size)\n",
    "    \n",
    "    return random_idx[:split_size] , random_idx[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats all set up.\n",
    "\n",
    "We should store the indexes now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set length : 6000\n",
      "Train set length : 54000\n"
     ]
    }
   ],
   "source": [
    "val_idx , train_idx = split_index(len(mnist_data) , 0.10)  \n",
    "\n",
    "print('Validation set length :' , len(val_idx))\n",
    "print('Train set length :' , len(train_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And its all set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the main purpoe of this notebook is to utilize the Cuda implementation which is not automatic in Pytorch, and have to be explicitly defined for implementation. So, lets define a model which would check for cuda availability and set the torch device as cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    \n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check our device then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = gpu_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! Our cuda is showing. Now for implementation we need to transfer data to cuda explicitly, so lets define a function like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_device(data , device):\n",
    "    if isinstance(data , (list , tuple)):\n",
    "        return [move_to_device(x , device) for x in data]\n",
    "    return data.to(device , non_blocking = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! \n",
    "Now lets set up our datalaoder and also implement our gpu integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "train_dl = DataLoader(mnist_data , batch_size = 512, sampler = train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "val_dl = DataLoader(mnist_data , batch_size = 512, sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have set our datalaoders.\n",
    "Now lets implement a class which would put them into gpu whenever iteratively called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpu_dataloader():\n",
    "    def __init__(self, dl , device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batches in self.dl:\n",
    "            yield move_to_device(batches , self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets transform the basic dataloaders in gpu dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = gpu_dataloader(train_dl , device)\n",
    "val_dataloader = gpu_dataloader(val_dl , device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And done!\n",
    "\n",
    "Now all we need is a metric function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!\n",
    "\n",
    "Now lets build our training part and validation part of the codes in two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model , train_dl , val_dl , loss_func , optim , num_epochs):\n",
    "    \n",
    "    acc = []\n",
    "    losses = []\n",
    "    for epochs in range(num_epochs):\n",
    "        \n",
    "        for xb , yb in train_dl:\n",
    "            ## making prediction\n",
    "            pred = model(xb)\n",
    "            \n",
    "            ## calculating loss function\n",
    "            loss = loss_func(pred , yb)\n",
    "    \n",
    "            ##calculating gradients\n",
    "            loss.backward()\n",
    "    \n",
    "            ##one step of optimization\n",
    "            optim.step()\n",
    "    \n",
    "            ##reset the gradient\n",
    "            optim.zero_grad()\n",
    "            \n",
    "        for val_x , val_y in val_dl:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                ##calculating the prediction\n",
    "                \n",
    "                val_pred = model(val_x)\n",
    "                \n",
    "                val_loss = loss_func(val_pred , val_y)\n",
    "                \n",
    "                ##storing the validation loss\n",
    "                losses.append(val_loss)\n",
    "                \n",
    "                ##getting accuracy\n",
    "                res = accuracy(F.softmax(val_pred , dim = 1) , val_y)\n",
    "                \n",
    "                ##storing the accuracy\n",
    "                acc.append(res)\n",
    "                \n",
    "        print('Epochs [ {} / {}] :- Loss : {:.4f} , Accuracy : {:.4f}'.format(epochs + 1 , num_epochs , val_loss , res))\n",
    "        \n",
    "    return acc , losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train our model, but before that we must move our model to cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = move_to_device(model , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda  ##checking if the model is in cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs [ 1 / 20] :- Loss : 0.4579 , Accuracy : 0.8641\n",
      "Epochs [ 2 / 20] :- Loss : 0.3700 , Accuracy : 0.9185\n",
      "Epochs [ 3 / 20] :- Loss : 0.3039 , Accuracy : 0.9239\n",
      "Epochs [ 4 / 20] :- Loss : 0.3642 , Accuracy : 0.8859\n",
      "Epochs [ 5 / 20] :- Loss : 0.2850 , Accuracy : 0.9185\n",
      "Epochs [ 6 / 20] :- Loss : 0.3545 , Accuracy : 0.8967\n",
      "Epochs [ 7 / 20] :- Loss : 0.3171 , Accuracy : 0.9266\n",
      "Epochs [ 8 / 20] :- Loss : 0.3041 , Accuracy : 0.9239\n",
      "Epochs [ 9 / 20] :- Loss : 0.4211 , Accuracy : 0.9130\n",
      "Epochs [ 10 / 20] :- Loss : 0.2550 , Accuracy : 0.9375\n",
      "Epochs [ 11 / 20] :- Loss : 0.3694 , Accuracy : 0.9212\n",
      "Epochs [ 12 / 20] :- Loss : 0.4135 , Accuracy : 0.9103\n",
      "Epochs [ 13 / 20] :- Loss : 0.4077 , Accuracy : 0.9076\n",
      "Epochs [ 14 / 20] :- Loss : 0.2950 , Accuracy : 0.9402\n",
      "Epochs [ 15 / 20] :- Loss : 0.3605 , Accuracy : 0.9293\n",
      "Epochs [ 16 / 20] :- Loss : 0.2665 , Accuracy : 0.9185\n",
      "Epochs [ 17 / 20] :- Loss : 0.4005 , Accuracy : 0.9185\n",
      "Epochs [ 18 / 20] :- Loss : 0.4177 , Accuracy : 0.8940\n",
      "Epochs [ 19 / 20] :- Loss : 0.2380 , Accuracy : 0.9293\n",
      "Epochs [ 20 / 20] :- Loss : 0.3898 , Accuracy : 0.8832\n"
     ]
    }
   ],
   "source": [
    "history = fit(model , train_dataloader , val_dataloader , loss_function , optimizer , 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
