{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continuous-specialist",
   "metadata": {},
   "source": [
    "## Depthwise Separable Convolution Tutorial using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-pakistan",
   "metadata": {},
   "source": [
    "In this notebook we are going to implement the depthwise separable convolution procedure utilized in the paper \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\" by Howard et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-orbit",
   "metadata": {},
   "source": [
    "Lets import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fleet-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary packages ##\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-binary",
   "metadata": {},
   "source": [
    "Its just an experimental process, hence, it wont be that big!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "concerned-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing the Depthwise Convolution ##\n",
    "## Here the convolution is done with each filter applied to each channel of the input ##\n",
    "\n",
    "## The change we implement is with the groups parameter of Conv2d where we choose the input channels as our groups ##\n",
    "## It hence applies the different filters on different channels of the input ##\n",
    "\n",
    "depthwise_conv = nn.Conv2d(in_channels = 32 , out_channels = 32 , kernel_size = 3 , stride = 1 , padding = 1 , groups = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-prophet",
   "metadata": {},
   "source": [
    "Lets try out if we have done it correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "political-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing the Depthwise Convolution ##\n",
    "\n",
    "inp = torch.randn((1 , 32 , 64 , 64))\n",
    "\n",
    "pred = depthwise_conv(inp)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-rocket",
   "metadata": {},
   "source": [
    "As expected!!\n",
    "\n",
    "The number of parameter for this is very small and it helps in efficient implementation.\n",
    "\n",
    "We can compare it also with a normal convolution.\n",
    "\n",
    "Lets do that!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promotional-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple convolution ##\n",
    "\n",
    "conv = nn.Conv2d(in_channels = 32 , out_channels = 32 , kernel_size = 3 , stride = 1 , padding = 1 , groups = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-height",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depthwise Convolution parameters :  torch.Size([32, 1, 3, 3])\n",
      "Normal Convolution parameters :  torch.Size([32, 32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print('Depthwise Convolution parameters : ' , depthwise_conv.weight.shape)\n",
    "print('Normal Convolution parameters : ' , conv.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-guess",
   "metadata": {},
   "source": [
    "The dependence on input channels is gone!!\n",
    "\n",
    "Well, the authors of the paper of MobileNet said that the process doesn't stop there and we need to do a pointwise 1 * 1 convolution to complete our approach.\n",
    "\n",
    "So, lets do that and check the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statistical-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing 1d convolution ##\n",
    "\n",
    "conv_1d = nn.Conv2d(in_channels = 32 , out_channels = 128 , kernel_size = 1 , stride = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "enclosed-spyware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing our 1d convolution ##\n",
    "\n",
    "inp1 = torch.randn((1 , 32 , 64 , 64))\n",
    "\n",
    "pred1 = conv_1d(inp1)\n",
    "\n",
    "pred1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-physiology",
   "metadata": {},
   "source": [
    "Perfect.\n",
    "\n",
    "Now lets check the total weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affected-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Parameters in Depthwise Separable Convolution :  4384\n",
      "No. of Parameters in Normal Convolution :  9216\n",
      "Ratio of Normal Convolution Param to Depthwise Param :  2.102189781021898\n"
     ]
    }
   ],
   "source": [
    "## Depthwise separable convolution weight ##\n",
    "\n",
    "depthwise_conv_weight = depthwise_conv.weight.shape\n",
    "\n",
    "depthwise_conv_param = depthwise_conv_weight[0] * depthwise_conv_weight[1] * depthwise_conv_weight[2] * depthwise_conv_weight[3]\n",
    "\n",
    "conv_1d_weight = conv_1d.weight.shape\n",
    "\n",
    "conv1d_param = conv_1d_weight[0] * conv_1d_weight[1] * conv_1d_weight[2] * conv_1d_weight[3]\n",
    "\n",
    "depthwise_total_param = depthwise_conv_param + conv1d_param\n",
    "\n",
    "\n",
    "\n",
    "## Normal convolution weight ##\n",
    "\n",
    "conv_weight = conv.weight.shape\n",
    "\n",
    "conv_param = conv_weight[0] * conv_weight[1] * conv_weight[2] * conv_weight[3]\n",
    "\n",
    "\n",
    "print('No. of Parameters in Depthwise Separable Convolution : ' , depthwise_total_param)\n",
    "print('No. of Parameters in Normal Convolution : ' , conv_param)\n",
    "print('Ratio of Normal Convolution Param to Depthwise Param : ' , conv_param / depthwise_total_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-royalty",
   "metadata": {},
   "source": [
    "Normal Convolution operation has twice the number of parameters.\n",
    "\n",
    "Wow!!\n",
    "\n",
    "Thats amazing!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-meaning",
   "metadata": {},
   "source": [
    "Now lets put it in a class such that we can use it in later cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tested-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Depthwise Separable COnvolution ##\n",
    "\n",
    "class DSConv(nn.Module):\n",
    "    \n",
    "    def __init__(self , in_channels , out_channels , kernel_size = 3 , stride = 1 , padding = 1):\n",
    "        super().__init__()\n",
    "        self.depthwise_sep_conv = nn.Sequential(nn.Conv2d(in_channels = in_channels , out_channels = in_channels , \n",
    "                                                          kernel_size = kernel_size , stride = stride , \n",
    "                                                          padding = padding , groups = in_channels),\n",
    "                                                nn.BatchNorm2d(in_channels),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Conv2d(in_channels = in_channels , out_channels = out_channels , \n",
    "                                                          kernel_size = 1 , stride = stride , padding = 1),\n",
    "                                                nn.BatchNorm2d(out_channels),\n",
    "                                                nn.ReLU()\n",
    "                                               )\n",
    "    def forward(self , x):\n",
    "        return self.depthwise_sep_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "together-cemetery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 66, 66])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing our module ##\n",
    "\n",
    "test_ds_conv = DSConv(32 , 128)\n",
    "\n",
    "pred = test_ds_conv(inp)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-appraisal",
   "metadata": {},
   "source": [
    "Boom!!\n",
    "\n",
    "Thats all!!\n",
    "\n",
    "Hopefully it would be easier to build the MobileNet models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
