{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Fitting a mesh of an object to a spherical mesh using Pytorch3d ##","metadata":{}},{"cell_type":"markdown","source":"In this notebook we are going to begin our journey in Pytorch3D. As a starter we are going to try to fit a mesh to a spherically initialized mesh. \n\n**Disclaimer** : I am a noob in Pytorch3d hence you will find my quite a bit of a struggle game. But, as always I will try my best to create the best of code.\n\n*(This notebook and the following notebooks on Pytorch3d are heavily influenced by the tutorials provided by Pytorch3d given in: https://pytorch3d.org/tutorials/ )* ","metadata":{}},{"cell_type":"markdown","source":"Installing Pytorch3d in Windows is a pain. Hence, I will be using Kaggle Kernels to help me in my task.\n\nTo set up Pytorch3d in Kaggle we need to install the necessary packages for it. We are going to take inspiration from [Kaggle_Pytorch3d](http://https://www.kaggle.com/code/aynur19/pytorch3d-3d-model-rendering/notebook?scriptVersionId=79722958) and go ahead with our work.","metadata":{}},{"cell_type":"code","source":"## Code copied from https://www.kaggle.com/code/aynur19/pytorch3d-3d-model-rendering/notebook?scriptVersionId=79722958 ##\n\nimport os\nimport sys\nimport torch\nfrom packaging import version\n\nneed_pytorch3d = False\npytorch3dVersion = '0.6.0'\n\ntry:\n    import pytorch3d as p3d\n    if version.parse(p3d.__version__) < version.parse(pytorch3dVersion):\n        need_pytorch3d = True\nexcept ModuleNotFoundError:\n    need_pytorch3d = True\n\n!curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n!tar xzf 1.10.0.tar.gz\nos.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n!pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'","metadata":{"execution":{"iopub.status.busy":"2022-06-11T00:26:10.894596Z","iopub.execute_input":"2022-06-11T00:26:10.895045Z","iopub.status.idle":"2022-06-11T00:44:55.034758Z","shell.execute_reply.started":"2022-06-11T00:26:10.894967Z","shell.execute_reply":"2022-06-11T00:44:55.033737Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"With all that aside, we can carry ahead on our project by importing all the necessary packages.","metadata":{}},{"cell_type":"code","source":"!pip install wget","metadata":{"execution":{"iopub.status.busy":"2022-06-11T00:45:23.077554Z","iopub.execute_input":"2022-06-11T00:45:23.077924Z","iopub.status.idle":"2022-06-11T00:45:34.045093Z","shell.execute_reply.started":"2022-06-11T00:45:23.077895Z","shell.execute_reply":"2022-06-11T00:45:34.044121Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## Importing the necessary packages ##\n\nimport wget\nimport torch\nimport pytorch3d\nfrom pytorch3d.io import load_obj , save_obj\nfrom pytorch3d.structures import Meshes\nfrom pytorch3d.utils import ico_sphere\nfrom pytorch3d.loss import chamfer_distance , mesh_edge_loss , mesh_laplacian_smoothing , mesh_normal_consistency\nfrom pytorch3d.ops import sample_points_from_meshes\n\nfrom tqdm import tqdm\nimport numpy as np\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:29:24.947554Z","iopub.execute_input":"2022-06-11T01:29:24.947906Z","iopub.status.idle":"2022-06-11T01:29:24.953619Z","shell.execute_reply.started":"2022-06-11T01:29:24.947878Z","shell.execute_reply":"2022-06-11T01:29:24.952452Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"With that we are done importing the necessary packages.\n\nNow, in this starter project we are going to fit a spherical mesh to a target mesh. So we must have some target mesh. There are many websites to get a target mesh, but I found the best one is this: https://people.sc.fsu.edu/~jburkardt/data/obj/obj.html . We can download one of the meshes and use it as our target mesh.\n\nWe are going to do just that. But how? By using **wget**. So, make sure you have wget installed using <code>pip install wget</code>.\n\nFor this work I chose the violin case obj from the website, so up next we will do just that.","metadata":{}},{"cell_type":"code","source":"## Downloading the target .obj file ##\n\nlink = 'https://people.sc.fsu.edu/~jburkardt/data/obj/violin_case.obj'\n\nfilename = wget.download(link)\n\nprint('\\n' + filename , 'is downloaded!')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:44:13.527056Z","iopub.execute_input":"2022-06-11T01:44:13.527435Z","iopub.status.idle":"2022-06-11T01:44:14.004019Z","shell.execute_reply.started":"2022-06-11T01:44:13.527398Z","shell.execute_reply":"2022-06-11T01:44:14.003233Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"If you have downloaded once don't download again, wget will keep on downloading it and your disk will get fill. So, just run the above code once and set your filename later to use it.\n\nNow we are going to load the .obj file using pytorch3d. The <code>load_obj</code> in <code>pytorch3d.io</code> loads the .obj and returns 3 things - vertices, faces and aux. ","metadata":{}},{"cell_type":"code","source":"## Setting the filename ##\n## Important if you have downloaded something before ##\n\nfilename = 'violin_case.obj'\n\n## Loading the .obj file ##\n\nvertices , faces , aux = load_obj(filename)\n\nprint('Target .obj is loaded!')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:10.047639Z","iopub.execute_input":"2022-06-11T01:55:10.047989Z","iopub.status.idle":"2022-06-11T01:55:10.071674Z","shell.execute_reply.started":"2022-06-11T01:55:10.047960Z","shell.execute_reply":"2022-06-11T01:55:10.070884Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"Now with this loaded, we need to create the Target Mesh out of the information we have. We are going to also normalize the vertices values for faster convergence.\n\nAlong with that we are going to create the initialized spherical mesh. \n\nAfter doing that we will also visualize the meshes, using a custom visualization function.","metadata":{}},{"cell_type":"code","source":"## Setting the default device ##\n\ndevice = torch.device('cpu')\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n\n## Normalizing the vertices ##\n\n## Finding the mean ##\nvertices_mean = vertices.mean(0)\n\n## Finding the max val ##\nvertices_max_val = max(vertices.abs().max(0)[0])\n\nvertices = vertices - vertices_mean / vertices_max_val\n\n\n## Shifting the vertices and the corresponding faces idx to gpu ##\nvertices = vertices.to(device)\nfaces_verts_idx = faces.verts_idx.to(device) \n\n## Creating target mesh ##\ntarget_mesh = Meshes(verts = [vertices] , faces = [faces_verts_idx])\n\n## Creating initial mesh ##\ninit_mesh = ico_sphere(4 , device = device)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:11.584119Z","iopub.execute_input":"2022-06-11T01:55:11.584491Z","iopub.status.idle":"2022-06-11T01:55:11.640182Z","shell.execute_reply.started":"2022-06-11T01:55:11.584460Z","shell.execute_reply":"2022-06-11T01:55:11.638063Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"## Visualizing meshes ##\n## Code inspired from : https://pytorch3d.org/tutorials/deform_source_mesh_to_target_mesh ##\n\ndef mesh_visualization(mesh , title = ''):\n    '''\n    Given a mesh, creates a visualization based\n    on fixed number sampling points.\n    '''\n    \n    ## Setting the number of sampling points ## \n    num_points = 15000\n    \n    ## Creates the points in the mesh ##\n    mesh_points = sample_points_from_meshes(mesh , num_samples = num_points)\n    \n    ## Grabs the x,y,z points ##\n    x, y, z = mesh_points.clone().detach().cpu().squeeze().unbind(1) \n    \n    ## Setting the \n    fig = plt.figure(figsize=(5, 5))\n    \n    ## Setting the 3d plot ##\n    ax = Axes3D(fig)\n    \n    ## Creating the scatter plot ##\n    ax.scatter3D(x, y, z)\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('z')\n    ax.set_title(title)\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:13.236555Z","iopub.execute_input":"2022-06-11T01:55:13.237165Z","iopub.status.idle":"2022-06-11T01:55:13.244860Z","shell.execute_reply.started":"2022-06-11T01:55:13.237126Z","shell.execute_reply":"2022-06-11T01:55:13.243806Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"Now let's visualize!!","metadata":{}},{"cell_type":"code","source":"## Plotting the target mesh ##\nmesh_visualization(target_mesh , 'Target Mesh')\nmesh_visualization(init_mesh , 'Init Mesh')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:15.250638Z","iopub.execute_input":"2022-06-11T01:55:15.254501Z","iopub.status.idle":"2022-06-11T01:55:16.255205Z","shell.execute_reply.started":"2022-06-11T01:55:15.254455Z","shell.execute_reply":"2022-06-11T01:55:16.252278Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"Amazing!!\nWe can now visualize the meshes. \n\nNext up what we need to do is set up the optimizer.\n\nInstead of directly optimizing the model as we do in Pytorch, here we need to optimize a mesh. But we can't just do it directly. We can optimize the mesh and change the vertex values by using the <code>.offset_verts</code>. The <code>.offset_verts</code> allows for changing the vertices by providing the offset or change that the vertices need to imbibe. This change can be calculated using the loss functions and the gradients. But, at the first epoch we need to set it as zero.\n\nSo what do we need to do next?\n* Create a value tensor which will provide the values for changing the vertices through offset_verts.\n* Create a optimizer with the parameter set as the value tensor created.","metadata":{}},{"cell_type":"code","source":"## Creating the value tensor ##\n\nvertices_value_changer_tensor = torch.full(init_mesh.verts_packed().shape , 0.0 , device = device , requires_grad = True)\n\n## Setting the optimizer ##\n\noptim = torch.optim.Adam([vertices_value_changer_tensor])","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:18.273371Z","iopub.execute_input":"2022-06-11T01:55:18.273918Z","iopub.status.idle":"2022-06-11T01:55:18.278638Z","shell.execute_reply.started":"2022-06-11T01:55:18.273883Z","shell.execute_reply":"2022-06-11T01:55:18.277891Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"Now, we must set up our loss function. Our loss function is very simple. It is the Chamfer Loss. But, to get a better and smoother mesh, we need to provide some regularizers. We provide regularizers using the <code>mesh_edge_loss , mesh_laplacian_smoothing , mesh_normal_consistency</code> functions.","metadata":{}},{"cell_type":"code","source":"## Loss function definition ##\n\ndef calculate_loss(initial_pointcloud , target_pointcloud , initial_mesh):\n    '''\n    Calculates the chamfered loss between the pointcloud samples of meshes.\n    Along with that adds in the regularizer given the mesh.\n    '''\n    chamfer_loss , _ = chamfer_distance(initial_pointcloud , target_pointcloud)\n    \n    edge_reg = mesh_edge_loss(initial_mesh)\n    \n    laplacian_reg = mesh_laplacian_smoothing(initial_mesh)\n    \n    normal_reg = mesh_normal_consistency(initial_mesh)\n    \n    total_loss = chamfer_loss + edge_reg + 0.1 * laplacian_reg + 0.01 * normal_reg\n    \n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:20.620616Z","iopub.execute_input":"2022-06-11T01:55:20.621614Z","iopub.status.idle":"2022-06-11T01:55:20.627670Z","shell.execute_reply.started":"2022-06-11T01:55:20.621565Z","shell.execute_reply":"2022-06-11T01:55:20.626853Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"Now we are all set, lets fit the training loop.","metadata":{}},{"cell_type":"code","source":"## Setting up the training loop ##\n\ndef fit(num_iter):\n    '''\n    Tries fitting the \n    '''\n    \n    loop = tqdm(range(num_iter))\n    \n    for each_iter in loop:\n        \n        optim.zero_grad()\n        \n        updated_init_mesh = init_mesh.offset_verts(vertices_value_changer_tensor)\n        \n        initial_pointcloud = sample_points_from_meshes(updated_init_mesh , num_samples = 15000)\n        \n        target_pointcloud = sample_points_from_meshes(target_mesh , num_samples = 15000)\n        \n        loss = calculate_loss(initial_pointcloud , target_pointcloud , updated_init_mesh)\n        \n        loop.set_description('Epoch : {} / {}'.format(each_iter + 1 , num_iter))\n        \n        loop.set_postfix(Loss = loss.item())\n        \n        if (each_iter + 1) % 500 == 0:\n            \n            mesh_visualization(target_mesh , 'Epoch : {} / {} --> Target Mesh'.format(each_iter  + 1, num_iter))\n            mesh_visualization(updated_init_mesh , 'Epoch : {} / {} -- > Init Mesh'.format(each_iter + 1 , num_iter))\n        \n        loss.backward()\n        \n        optim.step()\n    \n    final_vertices, final_faces = updated_init_mesh.get_mesh_verts_faces(0)\n    \n    final_vertices = final_vertices * vertices_max_val.to(device) + vertices_mean.to(device)\n    \n    return final_vertices.to('cpu') , final_faces.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:22.555365Z","iopub.execute_input":"2022-06-11T01:55:22.558537Z","iopub.status.idle":"2022-06-11T01:55:22.573600Z","shell.execute_reply.started":"2022-06-11T01:55:22.558483Z","shell.execute_reply":"2022-06-11T01:55:22.572736Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"## Running the script ##\n\nfinal_vertices , final_faces = fit(3000)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T01:55:25.847369Z","iopub.execute_input":"2022-06-11T01:55:25.847829Z","iopub.status.idle":"2022-06-11T01:56:46.309499Z","shell.execute_reply.started":"2022-06-11T01:55:25.847794Z","shell.execute_reply":"2022-06-11T01:56:46.308577Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"Amazing. Our mesh is very nicely fitted.\n\nSO, lets save our final .obj.","metadata":{}},{"cell_type":"code","source":"## Saving our .obj ##\n\nsave_obj('./fitted_mesh_final.obj' , final_vertices , final_faces)\n\nprint('Obj Saved Successfully!!')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T02:08:42.640459Z","iopub.execute_input":"2022-06-11T02:08:42.640816Z","iopub.status.idle":"2022-06-11T02:08:42.816388Z","shell.execute_reply.started":"2022-06-11T02:08:42.640786Z","shell.execute_reply":"2022-06-11T02:08:42.815548Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"## Downloading the obj file ##\n\nimport os\nos.chdir(r'/kaggle/working')\n\n!tar -czf obj.tar.gz fitted_mesh_final.obj\n\nfrom IPython.display import FileLink\n\nFileLink(r'obj.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T02:09:29.761745Z","iopub.execute_input":"2022-06-11T02:09:29.762090Z","iopub.status.idle":"2022-06-11T02:09:30.511008Z","shell.execute_reply.started":"2022-06-11T02:09:29.762062Z","shell.execute_reply":"2022-06-11T02:09:30.510111Z"},"trusted":true},"execution_count":99,"outputs":[]}]}