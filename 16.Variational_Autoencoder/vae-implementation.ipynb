{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Generating Chinese characters using Variational Autoencoder","metadata":{}},{"cell_type":"markdown","source":"In this notebook we are going to implement a simple Variational Autoencoder to generate Chinese Characters.","metadata":{}},{"cell_type":"markdown","source":"As always we are going to import the necessary packages.","metadata":{}},{"cell_type":"code","source":"## Importing necessary packages ##\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision.transforms import transforms\n\nfrom tqdm import tqdm\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With all that aside, lets move on and import our dataset.\n\nNow, our dataset is basically a csv file. So, we need to work around that before moving ahead.\n\nSo, lets first check the csv file using pandas.","metadata":{}},{"cell_type":"code","source":"## Checking the dataset csv file ##\n\ndata = pd.read_csv('../input/chinese-mnist/chineseMNIST.csv')\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, it is quite evident that there are 4096 pixels, meaning that the images are 64 * 64 in size. Since, it is MNIST inspired hence there is no chance of it being 3 channeled.\n\nThe entire dataset has 4098 columns, with one being the label. The character column is useless and needs to be removed.\n\nNow we will explore a bit more to get a good taste of the dataset.","metadata":{}},{"cell_type":"code","source":"## Deriving descriptive statistics ##\n\ndata.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the range of the dataset is not between 0 and 1. Hence a transformation is necessary.\n\nFurthermore, a lot of things are learnt from the dataset, like, there are total 15,000 images. Minimum value is 0.\n\nNow, we are going to set up our pytorch dataset.","metadata":{}},{"cell_type":"code","source":"## Setting up pytorch dataset ##\n\nclass chinese_dataset(Dataset):\n    \n    def __init__(self , path):\n        \n        super().__init__()\n        \n        self.dataset_csv = pd.read_csv(path)\n        \n        self.imgs = self.dataset_csv.iloc[: , :-2].values\n        \n        self.labels = self.dataset_csv['label']\n        \n    def __getitem__(self , idx):\n        \n        cyclic_idx = idx % len(self.imgs)\n        \n        unprocessed_img = self.imgs[cyclic_idx]\n        \n        processed_img = (unprocessed_img - np.min(unprocessed_img)) / (np.max(unprocessed_img) - np.min(unprocessed_img))\n        \n        img = torch.from_numpy(processed_img)\n        \n        label = img.clone()\n        \n        return img , label\n        \n    def __len__(self):\n        \n        return len(self.imgs)\n    \n## Creating our dataset instance ##\n\nchinese_data = chinese_dataset('../input/chinese-mnist/chineseMNIST.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets get insight on the dataset by visualizing the images.","metadata":{}},{"cell_type":"code","source":"## Exploring and Visualizing an image ##\n\nrandom_idx = int(np.random.randint(low = 0 , high = len(chinese_data) , size = 1))\n\nimg , label = chinese_data[random_idx]\n\nprint('A normal image sample has :' , img.shape)\n\nprint('Maximum value of the image is :' , torch.max(img))\n\nprint('Minimum value of the image is :' , torch.min(img))\n\nplt.imshow(img.reshape(64 , 64 , 1) , cmap = 'gray')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our dataset is ready.","metadata":{}},{"cell_type":"code","source":"## Implementing dataloader ##\n\nchinese_dataloader = DataLoader(dataset = chinese_data,\n                                batch_size = 16 ,\n                                shuffle = True)\n\n\n## Checking the length of dataloader ##\n\nprint('The dataloader has' , len(chinese_dataloader) , 'mini-batches!')\n\n\n## Visualizing a batch of data ##\n\nfor img , label in chinese_dataloader:\n    \n    fig , ax = plt.subplots(figsize = (4 , 4)) \n    \n    ax.set_xticklabels([])\n    \n    ax.set_yticklabels([])\n    \n    plt.imshow(make_grid(img.reshape(-1 , 1 , 64 , 64) , 4).permute(1 , 2 , 0))\n    \n    plt.show()\n    \n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now with that aside, we are going to implement our very own GPU Dataloader.","metadata":{}},{"cell_type":"code","source":"## Utility functions for GPU Dataloader ##\n\ndef get_device():\n    \n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    return torch.device('cpu')\n\n\ndevice = get_device()\n\ndef transfer_to_device(data , device):\n    \n    if isinstance(data , (list , tuple)):\n        return [transfer_to_device(each_data , device) for each_data in data]\n    return data.to(device)\n\n## Implementing GPU Dataloader ##\n\nclass GPUDataLoader:\n    \n    def __init__(self , dl = chinese_dataloader , device = device):\n        \n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \n        for batch in self.dl:\n            yield transfer_to_device(batch , self.device)\n            \n    def __len__(self):\n        \n        return len(self.dl)\n    \n## Setting the GPU dataloader object ##\n\nchinese_dl = GPUDataLoader()\n    \n## Checking the length of dataloader ##\n\nprint('The dataloader has' , len(chinese_dl) , 'mini-batches!')\n\n\n## Visualizing a batch of data ##\n\nfor img , label in chinese_dl:\n    \n    fig , ax = plt.subplots(figsize = (4 , 4)) \n    \n    ax.set_xticklabels([])\n    \n    ax.set_yticklabels([])\n    \n    plt.imshow(make_grid(img.to('cpu').reshape(-1 , 1 , 64 , 64) , 4).permute(1 , 2 , 0))\n    \n    plt.show()\n    \n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now its time to set up our Variational Autoencoder Model.\n\nLets go!","metadata":{}},{"cell_type":"code","source":"## Implementing Variational Autoencoder ##\n\nclass VAE(nn.Module):\n    \n    def __init__(self , in_feature , code_feature):\n        \n        super().__init__()\n        \n        self.hidden1 = nn.Linear(in_feature , code_feature * 8)\n        self.hidden2 = nn.Linear(code_feature * 8 , code_feature * 4)\n        self.mean = nn.Linear(code_feature * 4 , code_feature)\n        self.gamma = nn.Linear(code_feature * 4 , code_feature)\n        self.hidden3 = nn.Linear(code_feature , code_feature * 4)\n        self.hidden4 = nn.Linear(code_feature * 4 , code_feature * 8)\n        self.hidden5 = nn.Linear(code_feature * 8 , in_feature)\n        self.elu = nn.ELU()\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self , x):\n        x = self.hidden1(x)\n        x = self.elu(x)\n        x = self.hidden2(x)\n        x = self.elu(x)\n        x_mean = self.mean(x)\n        x_gamma = self.gamma(x)\n        x_sigma = torch.exp(x_gamma / 0.5)\n        dist = torch.distributions.Normal(x_mean , x_sigma)\n        code_layer = dist.rsample()\n        x = self.hidden3(code_layer)\n        x = self.elu(x)\n        x = self.hidden4(x)\n        x = self.elu(x)\n        out = self.hidden5(x)\n        \n        return x_gamma , x_mean , out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets create our model instance.","metadata":{}},{"cell_type":"code","source":"## Creating model object ##\n\nmodel = VAE(4096 , 32).to(device)\n\n## Testing model ##\n\nvar = torch.randn(4096).to(device)\n\ngamma , mean , out = model(var)\n\nprint('The shape of output is :' , out.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay cool!\n\nOur model is working perfectly it seems.\n\nNow we need to set our loss function.","metadata":{}},{"cell_type":"code","source":"## Defining loss function ##\n\nre_loss = nn.BCEWithLogitsLoss()\n\ndef latent_loss(gamma , mean):\n    \n    loss = 0.5 * torch.mean(torch.exp(gamma) + torch.square(mean) - 1 - gamma)\n    \n    return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets define our optimizer.","metadata":{}},{"cell_type":"code","source":"## Optimizer ##\n\noptim = torch.optim.Adam(model.parameters(), lr = 3e-4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets also define a visualization utility function.","metadata":{}},{"cell_type":"code","source":"## Visualization utility function ##\n\ndef vis_img(img):\n    \n    fig , ax = plt.subplots(figsize = (4 , 4)) \n    \n    ax.set_xticklabels([])\n    \n    ax.set_yticklabels([])\n    \n    plt.imshow(make_grid(img.detach().to('cpu').reshape(-1 , 1 , 64 , 64) , 4).permute(1 , 2 , 0))\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets train!","metadata":{}},{"cell_type":"code","source":"## Training our model ##\n\nnum_epochs = 50\n\nfor epoch in range(num_epochs):\n    \n    for img , target in chinese_dl:\n        \n        img = img.type(torch.cuda.FloatTensor)\n        \n        target = target.type(torch.cuda.FloatTensor)\n        \n        gamma , mean , out = model(img)\n        \n        #print(out.shape)\n        \n        #print(img.shape)\n        \n        #print(target.shape)\n        \n        reconstruction_loss = re_loss(out , target)\n        \n        code_loss = latent_loss(gamma , mean)\n        \n        loss = reconstruction_loss + code_loss\n        \n        optim.zero_grad()\n        \n        loss.backward()\n        \n        optim.step()\n        \n    print('Epoch : {} / {} --> Loss : {}'.format(epoch + 1  , num_epochs , loss.item()))        \n            \n    vis_img(img)       \n    \n    vis_img(out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}