{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef32d65",
   "metadata": {},
   "source": [
    "## Demostration of Spatial Transformer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5688c2d5",
   "metadata": {},
   "source": [
    "In this notebook, I am going to showcase the highly popular **Spatial Transformer Network** using Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c9431",
   "metadata": {},
   "source": [
    "A **Spatial Transformer Network** is nothing but an addon to the normal neural network architecture. What it does is mainly reorient the transformed data to a setting which helps the network to predict better scores.\n",
    "\n",
    "In this notebook, we are going to use it on EMNIST dataset (with letters split) and is going to set it up just after the input images.\n",
    "\n",
    "For a better intuition about Spatial Transformers you can have a look at the paper: https://arxiv.org/pdf/1506.02025.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the necessary packages ##\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8adb8",
   "metadata": {},
   "source": [
    "As always the first thing to do is to set up the dataset.\n",
    "\n",
    "Since, we are going to use the EMNIST dataset, it is already preloaded in torchvision, our task is very easy-- just by using the <code>EMNIST</code> method from the <code>torchvision.datasets</code> package. \n",
    "\n",
    "But, since we want the dataset to have certain aspect ratio/size we would like to define some transforms to give as an argument to the EMNIST method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining transformations ##\n",
    "\n",
    "aug = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees = 30,\n",
    "                            scale = (0.5 , 1.5)\n",
    "                           ),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "## Loading the train dataset to the disk ##\n",
    "\n",
    "emnist_letter_train_dataset = EMNIST(root = 'train_data' ,\n",
    "                               split = 'letters' ,\n",
    "                               train = True , \n",
    "                               download = True , \n",
    "                               transform = aug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb5d11",
   "metadata": {},
   "source": [
    "With the data loaded lets check our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the length of the dataset ##\n",
    "\n",
    "print('Training dataset length :' , len(emnist_letter_train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009f24d",
   "metadata": {},
   "source": [
    "Lets check the shape of a datapoint. I assume it would be a tuple, where the first part is the image and the second part would be the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b427f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting a random integer ##\n",
    "\n",
    "rand_idx = int(np.random.randint(low = 0 , high = len(emnist_letter_train_dataset) , size = 1))\n",
    "\n",
    "## Getting a datapoint from the training set ##\n",
    "\n",
    "train_datapoint = emnist_letter_train_dataset[rand_idx]\n",
    "\n",
    "print('Shape of the train datapoint is :' , len(train_datapoint))\n",
    "print('Datatype of the train datapoint is :' , type(train_datapoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe7331",
   "metadata": {},
   "source": [
    "As guessed it is a tuple of size 2. \n",
    "\n",
    "Now let's see what's inside the tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c571e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the inside of the datapoint ##\n",
    "\n",
    "## Extracting the image data ##\n",
    "\n",
    "img = train_datapoint[0]\n",
    "\n",
    "print('The shape of the image is :' , img.shape)\n",
    "\n",
    "## Extracting the label ##\n",
    "\n",
    "label = train_datapoint[1]\n",
    "\n",
    "print('The label is :' , label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163c376",
   "metadata": {},
   "source": [
    "Since, this is similar to the much popular MNIST dataset, the images are grayscale with dimension 28 * 28. \n",
    "\n",
    "Lets visualize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing the image ##\n",
    "\n",
    "plt.title(label)\n",
    "\n",
    "plt.imshow(img.permute(1 , 2 , 0) , cmap = 'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f8685",
   "metadata": {},
   "source": [
    "Now to feed into a network we need to create a dataloader which sends in batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9482bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the train dataloader ##\n",
    "\n",
    "train_dataloader = DataLoader(dataset = emnist_letter_train_dataset,\n",
    "                              batch_size = 16 , \n",
    "                              shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c8d25",
   "metadata": {},
   "source": [
    "Lets check the length of the dataloaders!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the length of the dataloaders ##\n",
    "\n",
    "print('Length of the train dataloader :' , len(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2533d9",
   "metadata": {},
   "source": [
    "Okay cool.\n",
    "\n",
    "But its going to be really awesome if we could visualize a set of the data from the dataloader. So, lets do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567317ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an utility function to visualize a set of data ##\n",
    "\n",
    "def visualize(img_batch):\n",
    "    '''\n",
    "    Function to visualize a batch (taken as 16) of image data.\n",
    "    '''\n",
    "    \n",
    "    fig , ax = plt.subplots(figsize = (4 , 4))\n",
    "    plt.imshow(make_grid(img_batch.detach().to('cpu') , 4).permute(1 , 2 , 0))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "## Visualizing a batch of images ##\n",
    "\n",
    "for img , _ in train_dataloader:\n",
    "    \n",
    "    visualize(img)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e919e",
   "metadata": {},
   "source": [
    "With that out of the way, let's head down to the main part of the project-- the creation of the network.\n",
    "\n",
    "Our main network is going to be very simple but the highlight of the model is the Spatial Transformer module, which is comprised of three parts namely:\n",
    "\n",
    "- Localization Network\n",
    "- Grid Generator\n",
    "- Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72109505",
   "metadata": {},
   "source": [
    "![](stn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc025dcf",
   "metadata": {},
   "source": [
    "The 2nd and the 3rd part, namely, Grid Generator and the Sampler are easily taken care of by the ```affine_grid``` and the ```grid_sample``` methods of the ```torch.nn.functional``` package respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d079a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the network module ##\n",
    "\n",
    "class network(nn.Module):\n",
    "    '''\n",
    "    The network incorporating the Spatial Transformer Network module along with the primary backbone.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        The constructor method. In this the general backbone of the network is created with the class variable net,\n",
    "        and the localization network of spatial transformer module is created with the class variable localization_network.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        ## Creating the spine network ##\n",
    "        \n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels = 1,\n",
    "                                           out_channels = 8,\n",
    "                                           kernel_size = 3,\n",
    "                                           stride = 1,\n",
    "                                           padding = 1),\n",
    "                                 nn.BatchNorm2d(num_features = 8),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d(kernel_size = 2,\n",
    "                                              stride = 2),   ## (14 , 14 , 8)\n",
    "                                 \n",
    "                                 ############################################\n",
    "                                 \n",
    "                                 nn.Conv2d(in_channels = 8,\n",
    "                                           out_channels = 16,\n",
    "                                           kernel_size = 3,\n",
    "                                           stride = 1,\n",
    "                                           padding = 1),\n",
    "                                 nn.BatchNorm2d(num_features = 16),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d(kernel_size = 2,\n",
    "                                              stride = 2), ## (7 , 7 , 16)\n",
    "                                 \n",
    "                                 ############################################\n",
    "                                 \n",
    "                                 nn.Conv2d(in_channels = 16,\n",
    "                                           out_channels = 32,\n",
    "                                           kernel_size = 3,\n",
    "                                           stride = 1,\n",
    "                                           padding = 1),\n",
    "                                 nn.BatchNorm2d(num_features = 32),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d(kernel_size = 2,\n",
    "                                              stride = 2), ## (3 , 3 , 32)\n",
    "                                 \n",
    "                                 \n",
    "                                 ############################################\n",
    "                                 \n",
    "                                 nn.Conv2d(in_channels = 32,\n",
    "                                           out_channels = 64,\n",
    "                                           kernel_size = 3,\n",
    "                                           stride = 1,\n",
    "                                           padding = 1),\n",
    "                                 nn.BatchNorm2d(num_features = 64),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d(kernel_size = 2,\n",
    "                                              stride = 2), ## (1 , 1 , 64)\n",
    "                                 \n",
    "                                 ############################################\n",
    "                                 \n",
    "                                 nn.Flatten(),\n",
    "                                 nn.Linear(64 , 27)\n",
    "                                )\n",
    "        \n",
    "        ## Creating the localization network of spatial transformer module ##\n",
    "        \n",
    "        self.localization_network = nn.Sequential(nn.Conv2d(in_channels = 1,\n",
    "                                                            out_channels = 8,\n",
    "                                                            kernel_size = 9,\n",
    "                                                            stride = 1),\n",
    "                                    nn.BatchNorm2d(num_features = 8),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2,\n",
    "                                                 stride = 2),   ## (10 , 10 , 8)\n",
    "                                                \n",
    "                                    ############################################\n",
    "                                                  \n",
    "                                    nn.Conv2d(in_channels = 8,\n",
    "                                                            out_channels = 16,\n",
    "                                                            kernel_size = 7,\n",
    "                                                            stride = 1),\n",
    "                                    nn.BatchNorm2d(num_features = 16),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2,\n",
    "                                                 stride = 2),   ## (2 , 2 , 16)\n",
    "                                                \n",
    "                                    ############################################\n",
    "                                    \n",
    "                                    nn.Flatten(),\n",
    "                                    nn.Linear(2 * 2 * 16 , 16),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(16 , 6)              \n",
    "                                    )\n",
    "        \n",
    "        ## Initializing the weights and bias of the output of the localization network with identity transformation ##\n",
    "        \n",
    "        self.localization_network[-1].weight.data.zero_()\n",
    "        self.localization_network[-1].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    \n",
    "    def forward_stn(self , inp):\n",
    "        '''\n",
    "        Defines the forward pass of the Spatial Transformer Network.\n",
    "        This is necessary to finally visualize the output of the STN.\n",
    "        '''\n",
    "        \n",
    "        out = self.localization_network(inp)\n",
    "        \n",
    "        ## Reshape the output to have the shape (batch_num , 2 rows , 3 columns) ##\n",
    "\n",
    "        out = out.reshape(-1 , 2 , 3)\n",
    "        \n",
    "        ## Grid Generator ##\n",
    "        \n",
    "        generated_grid = F.affine_grid(out , inp.size())\n",
    "        \n",
    "        ## Sampler ##\n",
    "        \n",
    "        out = F.grid_sample(inp , generated_grid)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(self , inp):\n",
    "        '''\n",
    "        Defines one forward pass through the network.\n",
    "        '''\n",
    "        \n",
    "        ## We decided to put the STN after the input image ##\n",
    "        \n",
    "        inp = self.forward_stn(inp)\n",
    "        \n",
    "        out = self.net(inp)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580ffb2",
   "metadata": {},
   "source": [
    "Done. Our model is created.\n",
    "\n",
    "Now lets set our model and put it to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bed459",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the device ##\n",
    "\n",
    "def get_device():\n",
    "    '''\n",
    "    Sets the torch.device to cuda or cpu.\n",
    "    '''\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    \n",
    "    return torch.device('cpu')\n",
    "\n",
    "## Setting the device ##\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "## Putting the model to the device ##\n",
    "\n",
    "model = network().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900ca71",
   "metadata": {},
   "source": [
    "Done. Our model object is created and is put to the GPU (I am certain its a GPU, because I have one. :P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320fe6f",
   "metadata": {},
   "source": [
    "Now lets set our loss function and our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the loss function ##\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "## Setting the optimizer ##\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters() , lr = 3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe96cd6",
   "metadata": {},
   "source": [
    "And we are all set to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7003f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the training phase ##\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loop = tqdm(train_dataloader)\n",
    "    \n",
    "    for img , label in loop:\n",
    "        \n",
    "        img = img.to(device)\n",
    "        \n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model(img)\n",
    "        \n",
    "        #print('Maximum label value :' , torch.max(label))\n",
    "        \n",
    "        loss = loss_func(pred , label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        loop.set_description('Epoch : {} / {}'.format(epoch + 1 , epochs))\n",
    "        \n",
    "        loop.set_postfix(loss = loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
