{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we understand the param_groups of the optimizer subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary packages ##\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "----------------Tensor 1-----------------------\n",
      "tensor([[ 0.8125,  0.1984,  0.9420],\n",
      "        [-0.4620,  0.5406, -1.3698],\n",
      "        [ 0.4793,  0.2847,  0.4569]], requires_grad=True)\n",
      "-----------------------------------------------\n",
      "----------------Tensor 2-----------------------\n",
      "tensor([[-1.2722,  0.8374, -0.6923],\n",
      "        [-1.0081,  0.3518, -1.0024],\n",
      "        [ 0.6581, -0.1415,  0.2916]], requires_grad=True)\n",
      "-----------------------------------------------\n",
      "----------------Tensor 3-----------------------\n",
      "tensor([[ 1.1640, -0.8308,  0.1520],\n",
      "        [-0.7118,  1.5370, -0.1858],\n",
      "        [ 1.0072, -1.2591, -2.5712]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## Defining 3 tensors ## \n",
    "\n",
    "tensor_1 = torch.randn(3, 3 , requires_grad = True)\n",
    "tensor_2 = torch.randn(3, 3 , requires_grad = True)\n",
    "tensor_3 = torch.randn(3, 3 , requires_grad = True)\n",
    "\n",
    "## Checking the values ##\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "print('----------------Tensor 1-----------------------')\n",
    "print(tensor_1)\n",
    "print('-----------------------------------------------')\n",
    "print('----------------Tensor 2-----------------------')\n",
    "print(tensor_2)\n",
    "print('-----------------------------------------------')\n",
    "print('----------------Tensor 3-----------------------')\n",
    "print(tensor_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define our optimizer.\n",
    "\n",
    "We will be looking at two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': [tensor([[ 0.8125,  0.1984,  0.9420],\n",
      "        [-0.4620,  0.5406, -1.3698],\n",
      "        [ 0.4793,  0.2847,  0.4569]], requires_grad=True), tensor([[-1.2722,  0.8374, -0.6923],\n",
      "        [-1.0081,  0.3518, -1.0024],\n",
      "        [ 0.6581, -0.1415,  0.2916]], requires_grad=True)], 'lr': 0.0003, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n"
     ]
    }
   ],
   "source": [
    "## Setting first optimizer ##\n",
    "\n",
    "optimizer_1 = optim.SGD([tensor_1, tensor_2], lr = 3e-4)\n",
    "\n",
    "## printing the parameter groups ##\n",
    "\n",
    "print(optimizer_1.param_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so it gives a list of dictionaries.\n",
    "\n",
    "The list has only one set of values. This is because we set uniform attribute for both the tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': [tensor([[ 0.8125,  0.1984,  0.9420],\n",
      "        [-0.4620,  0.5406, -1.3698],\n",
      "        [ 0.4793,  0.2847,  0.4569]], requires_grad=True)], 'lr': 0.0002, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, {'params': [tensor([[-1.2722,  0.8374, -0.6923],\n",
      "        [-1.0081,  0.3518, -1.0024],\n",
      "        [ 0.6581, -0.1415,  0.2916]], requires_grad=True)], 'lr': 0.0003, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, {'params': [tensor([[ 1.1640, -0.8308,  0.1520],\n",
      "        [-0.7118,  1.5370, -0.1858],\n",
      "        [ 1.0072, -1.2591, -2.5712]], requires_grad=True)], 'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}]\n"
     ]
    }
   ],
   "source": [
    "## Setting optimizer##\n",
    "\n",
    "optimizer_2 = optim.Adam([{'params': tensor_1, 'lr': 2e-4},\n",
    "                          {'params': tensor_2, 'lr': 3e-4},\n",
    "                          {'params': tensor_3, 'lr': 1e-2}])\n",
    "\n",
    "## printing the parameter groups ##\n",
    "\n",
    "print(optimizer_2.param_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this has 3 values because we have set separate params with separate lr attribute.\n",
    "\n",
    "So, to get like the attributes for the tensor_2 we need to index to that point.\n",
    "\n",
    "```python\n",
    "## indexing to Tensor_2 attributes ##\n",
    "optimizer_2.param_groups[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [tensor([[-1.2722,  0.8374, -0.6923],\n",
       "          [-1.0081,  0.3518, -1.0024],\n",
       "          [ 0.6581, -0.1415,  0.2916]], requires_grad=True)],\n",
       " 'lr': 0.0003,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## indexing to Tensor_2 attributes ##\n",
    "\n",
    "optimizer_2.param_groups[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that this is a dictionary. \n",
    "\n",
    "So we can get into the values of any of the element by just indexing to it and changing the value.\n",
    "\n",
    "So, lets do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [tensor([[-1.2722,  0.8374, -0.6923],\n",
       "          [-1.0081,  0.3518, -1.0024],\n",
       "          [ 0.6581, -0.1415,  0.2916]], requires_grad=True)],\n",
       " 'lr': 1,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Changing the value of learning rate ##\n",
    "\n",
    "optimizer_2.param_groups[1]['lr'] = 1\n",
    "\n",
    "optimizer_2.param_groups[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And its changed.\n",
    "\n",
    "This concept is neccessary when we are implementing learning rate scheduler.\n",
    "\n",
    "In the adjacent python file we are going to implement the learning rate finder much like that of the `fast.ai` package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
