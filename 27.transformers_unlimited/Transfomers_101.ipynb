{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15cd5f77",
   "metadata": {},
   "source": [
    "### Transformers 101: Using Transformers for text generation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42426da0",
   "metadata": {},
   "source": [
    "Transformers have taken up the Deep Learning field. But, to be honest I always found them difficult to understand. So, that's why I tried reading it over and over again and filled in the void in my understanding. In this project I will try to go through each step at a time and try to understand the Transformer network by coding them with delicate explanations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29e069b6",
   "metadata": {},
   "source": [
    "To understand our work we are going to use the [Poems dataset](https://www.kaggle.com/datasets/charunisa/english-poems-dataset).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d5141a6",
   "metadata": {},
   "source": [
    "Without further adieu lets get started with our work and import the necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab60884",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary packages ##\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "## For displaying exact values  and not in exponentiations##\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "## Setting the device ##\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "810a03fb",
   "metadata": {},
   "source": [
    "#### Loading and Understanding our dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ac15dfe",
   "metadata": {},
   "source": [
    "As a first step we need to look at what we are doing and how our dataset looks like. I like to summarize it as follows.\n",
    "\n",
    "- **Main Goal** : Generate English poems using Transformer Networks.\n",
    "- **Data Loading** (_Not DataLoader_) : Read the text file and merge the contents at a single place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782c75d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length is 18033\n"
     ]
    }
   ],
   "source": [
    "## Reading the text file ##\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(\"poems.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    for i, each_line in enumerate(file):\n",
    "        each_line = \"<start> \" + each_line.lower().strip(\"\\n\") + \" <end>\"\n",
    "        data.extend(each_line.split())\n",
    "\n",
    "print(f\"Total dataset length is {len(data)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "946a2000",
   "metadata": {},
   "source": [
    "Now our data is stored as a single big text corpus. What we want to do, is randomly pick up a sub-set of it and feed it to the transformer module to make it generate new words.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69aa13c3",
   "metadata": {},
   "source": [
    "But before that we must build our word corpus or vocabulary. The easiest way of doing it is simply making a set of all the unique words that there are in the corpus and then giving them an index. Moreover a mapping of word to index is necessary to achieve this final goal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34f66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length is 4113\n"
     ]
    }
   ],
   "source": [
    "## Making our vocabulary ##\n",
    "\n",
    "vocab = set()\n",
    "vocab = sorted(list(set(data)))\n",
    "vocab.remove(\"<start>\")\n",
    "vocab.remove(\"<end>\")\n",
    "vocab.insert(0, \"<start>\")\n",
    "vocab.insert(1, \"<end>\")\n",
    "print(f\"Vocabulary length is {len(vocab)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80cfa5a6",
   "metadata": {},
   "source": [
    "Now let us setup a vocabulary word to index mapping and vice versa for later use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85e2e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start word index : 0, end word index : 1\n",
      "Word at index 0 : <start>, Word at index 1 : <end>\n"
     ]
    }
   ],
   "source": [
    "## Word 2 index mapping ##\n",
    "\n",
    "word_2_idx = {k: v for v, k in enumerate(vocab)}\n",
    "\n",
    "print(\n",
    "    f\"Start word index : {word_2_idx['<start>']}, end word index : {word_2_idx['<end>']}\"\n",
    ")\n",
    "## Index 2 word mapping for generation ##\n",
    "\n",
    "idx_2_word = {v: k for k, v in word_2_idx.items()}\n",
    "print(f\"Word at index 0 : {idx_2_word[0]}, Word at index 1 : {idx_2_word[1]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a5fc389",
   "metadata": {},
   "source": [
    "Perfect we are very nicely setup. Now the idea is to create a Pytorch Dataset instance which would do the following.\n",
    "\n",
    "- [ ] Given a data corpus and a sequence length, it would randomly pluck a sequence of data (of sequence length) from the data corpus and return it along with the labels which are nothing but 1 index shifted of the data corpus. This would become more clear on code-up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1c0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch dataset ##\n",
    "\n",
    "\n",
    "class PoemsDataset(Dataset):\n",
    "    \"\"\"The custom poems dataset\"\"\"\n",
    "\n",
    "    def __init__(self, data_corpus, sequence_length):\n",
    "        super().__init__()\n",
    "        self.data_corpus = data_corpus\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = torch.tensor(\n",
    "            [word_2_idx[w] for w in self.data_corpus[idx : idx + self.sequence_length]]\n",
    "        )\n",
    "        label = torch.tensor(\n",
    "            [\n",
    "                word_2_idx[w]\n",
    "                for w in self.data_corpus[idx + 1 : idx + 1 + self.sequence_length]\n",
    "            ]\n",
    "        )\n",
    "        return inp, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_corpus) - (self.sequence_length + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be63bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility function to show data ##\n",
    "\n",
    "\n",
    "def show_data(data, verbose=True):\n",
    "    \"\"\"Given a data tensor, maps them to string and prints them.\"\"\"\n",
    "    str_data = [idx_2_word[each_word.item()] for each_word in data.data]\n",
    "    if verbose:\n",
    "        print(str_data)\n",
    "    else:\n",
    "        return str_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dbf3aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Raw data : (tensor([ 228, 4011, 2141, 1634, 3773, 3507,  275,    1]), tensor([4011, 2141, 1634, 3773, 3507,  275,    1,    0]))\n",
      "Inputs ->\n",
      "['art', 'with', 'me', 'here', 'upon', 'the', 'banks', '<end>']\n",
      "Labels ->\n",
      "['with', 'me', 'here', 'upon', 'the', 'banks', '<end>', '<start>']\n"
     ]
    }
   ],
   "source": [
    "## For reproducing the same code ##\n",
    "torch.manual_seed(97)\n",
    "\n",
    "## Dataset ##\n",
    "\n",
    "poems_data = PoemsDataset(data, 8)\n",
    "\n",
    "## Testing our dataset ##\n",
    "random_idx = int(torch.randint(low=0, high=len(poems_data), size=(1,)))\n",
    "random_idx\n",
    "\n",
    "print(f\" Raw data : {poems_data[random_idx]}\")\n",
    "\n",
    "print(\"Inputs ->\")\n",
    "show_data(poems_data[random_idx][0])\n",
    "\n",
    "print(\"Labels ->\")\n",
    "show_data(poems_data[random_idx][1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caf530fd",
   "metadata": {},
   "source": [
    "Now since we have already gotten our hands dirty with the Dataset, it would be of the utmost importance to build up our Dataloader module too, which would feed in such batches of sequences for feeding to the Transformer network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b6c5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building dataloader ##\n",
    "\n",
    "\n",
    "def build_dl(dataset, batch_size=4, shuffle=True):\n",
    "    \"\"\"Returns the dataloader object.\"\"\"\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f813ffb3",
   "metadata": {},
   "source": [
    "Perfect, our dataloader is also curated.\n",
    "\n",
    "Now it would also be nice to see how our dataloader is sending out the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8074d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : torch.Size([4, 8]) and Labels shape : torch.Size([4, 8])\n",
      "----------------------\n",
      "Input :\t['did', 'i', 'count!', '<end>', '<start>', 'blest', 'was', 'i']\n",
      "Label :\t['i', 'count!', '<end>', '<start>', 'blest', 'was', 'i', 'then']\n",
      "----------------------\n",
      "Input :\t['mortality;', '<end>', '<start>', 'another', 'race', 'hath', 'been,', 'and']\n",
      "Label :\t['<end>', '<start>', 'another', 'race', 'hath', 'been,', 'and', 'other']\n",
      "----------------------\n",
      "Input :\t['on', 'the', 'farm,', 'she', 'did', '<end>', '<start>', 'a']\n",
      "Label :\t['the', 'farm,', 'she', 'did', '<end>', '<start>', 'a', 'childlike']\n",
      "----------------------\n",
      "Input :\t['it', 'die', 'away,', '<end>', '<start>', 'and', 'fade', 'into']\n",
      "Label :\t['die', 'away,', '<end>', '<start>', 'and', 'fade', 'into', 'the']\n"
     ]
    }
   ],
   "source": [
    "## Dataloader check ##\n",
    "\n",
    "poems_dl = build_dl(poems_data)\n",
    "\n",
    "for inp, labels in poems_dl:\n",
    "\n",
    "    print(f\"Input shape : {inp.shape} and Labels shape : {labels.shape}\")\n",
    "\n",
    "    for each_inp, each_label in zip(inp, labels):\n",
    "        print(\"----------------------\")\n",
    "        print(\"Input :\\t\", end=\"\")\n",
    "        show_data(each_inp)\n",
    "        print(\"Label :\\t\", end=\"\")\n",
    "        show_data(each_label)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a89463ec",
   "metadata": {},
   "source": [
    "Perfect!! Our dataloader performs exactly like we want.\n",
    "\n",
    "But before I forget, let me explain the structure of the input and the output.\n",
    "\n",
    "So what are we building? **Generation** model which would generate beautiful poems.\n",
    "\n",
    "Now the model can't just burp out everything all at once (even though it would have been nice!). It generates one word at a time. It is very similar to how we write something (one unit of word/sentence at a time)!\n",
    "\n",
    "Now what we want to teach the model is that by taking the current word and all the words the model has predicted, the model must output the next word. So, the inputs are basically increasing with each step, at first step input is -> 'from', at second step -> 'from','his' , at third step it is 'from', 'his', \"father's\", and so on. And the corresponding output next word is given by the label, 1st step -> 'his', 2nd step -> \"father's\" , 3rd step -> 'eyes!' and so on.\n",
    "\n",
    "I hope this makes everything clear, since, it will be at the core of the transformer block.\n",
    "\n",
    "In the next few cell I will try to show how you can do this type of input and output combination using basic pytorch functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6143645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inp shape : torch.Size([8])\n",
      "------------\n",
      "Current Input :\ttensor([   0., 1739., 1571., 4007.,   82.,  379., 4049., 1283.])\n",
      "Mask :\ttensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "Cascaded Input :\ttensor([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0., 1739.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0., 1739., 1571.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0., 1739., 1571., 4007.,    0.,    0.,    0.,    0.],\n",
      "        [   0., 1739., 1571., 4007.,   82.,    0.,    0.,    0.],\n",
      "        [   0., 1739., 1571., 4007.,   82.,  379.,    0.,    0.],\n",
      "        [   0., 1739., 1571., 4007.,   82.,  379., 4049.,    0.],\n",
      "        [   0., 1739., 1571., 4007.,   82.,  379., 4049., 1283.]])\n"
     ]
    }
   ],
   "source": [
    "## Checking the masking of the inputs ##\n",
    "\n",
    "test_data = poems_data[0]\n",
    "\n",
    "test_inp, test_label = test_data\n",
    "test_inp, test_label = test_inp.float(), test_label.float()\n",
    "\n",
    "print(f\"test_inp shape : {test_inp.shape}\")\n",
    "\n",
    "print(f\"------------\")\n",
    "print(f\"Current Input :\\t{test_inp}\")\n",
    "\n",
    "## Making the input to have the required orientation ##\n",
    "mask = torch.tril(torch.ones((8, 8)))\n",
    "\n",
    "print(f\"Mask :\\t{mask}\")\n",
    "\n",
    "## Dot product of mask and test_inp will do the cascading ##\n",
    "cascaded_inp = mask * test_inp\n",
    "\n",
    "print(f\"Cascaded Input :\\t{cascaded_inp}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35c0b35d",
   "metadata": {},
   "source": [
    "Perfect, we could already do something like that. But the thing is, we dont want to somehow compress our multi-worded context for predicting the next word into a singular value. Such that even though we are considering multiple words, we would actually be giving a single number. So, how to do that?\n",
    "\n",
    "- One simple way is to just add up the columns. And here we are going to do just the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417cbf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attended inp : tensor([    0.,  1739.,  3310.,  7317.,  7399.,  7778., 11827., 13110.])\n"
     ]
    }
   ],
   "source": [
    "## Adding up the columns to convert to single element ##\n",
    "\n",
    "print(f\"Attended inp : {cascaded_inp.sum(1)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "572df01a",
   "metadata": {},
   "source": [
    "But this entire setup was a two step setup. Can we somehow merge it to a single step? The answer is : **DOT** Products!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8563921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "Attended inp : tensor([    0.,  1739.,  3310.,  7317.,  7399.,  7778., 11827., 13110.])\n"
     ]
    }
   ],
   "source": [
    "## Doing dot product to do the same thing ##\n",
    "\n",
    "test_data = poems_data[0]\n",
    "\n",
    "test_inp, test_label = test_data\n",
    "test_inp, test_label = test_data\n",
    "test_inp, test_label = test_inp.float(), test_label.float()\n",
    "\n",
    "print(test_inp.shape)\n",
    "\n",
    "attended_inp = mask @ test_inp.unsqueeze(1)\n",
    "print(f\"Attended inp : {attended_inp.squeeze(1)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a51b7d1",
   "metadata": {},
   "source": [
    "And this is exactly the same as the result before. Amazing!!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dddeeb79",
   "metadata": {},
   "source": [
    "Spoiler! Spoiler! Spoiler! This simplistic formulation is nothing but the Masked Attention, at the heart of Transformer decoder.\n",
    "\n",
    "But its a bit more nuanced. Here, since I was taking \"ones\" as my mask, I was just doing averaging. Averaging is very simple. In attention there is no 1's, instead we have learned values. This learnt values are done through a product of two Matrices of batches called the **Query** and the **Key**. Now, for conversion to probability the product is passed through a Softmax.\n",
    "\n",
    "The thing is, we just want values of the mask in the lower triangular matrix and all the values of the mask in the upper triangular matrix must be 0. So how can we achieve this directly after softmax? The easiest way to do it is after doing the dot product between the matrices we set everything above the diagonal to -inf, as such when passed through the softmax all these values will become 0, exactly to what we need. In the next cell lets try to do this for sanity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb0cf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key :\t\n",
      "tensor([[ 0.0493,  2.3374,  1.5298,  0.2551,  0.0994, -0.3862, -1.7110,  1.5092],\n",
      "        [-1.4439,  1.1032, -0.7929,  1.1246,  0.3582,  2.4612,  0.1289, -0.4013],\n",
      "        [-0.2494, -0.4767,  1.3613,  0.1978,  1.3810,  0.5879, -0.4244,  0.4247],\n",
      "        [ 1.3456,  1.2036, -0.9834, -0.9720, -0.6042, -0.2600,  0.1238,  1.3787],\n",
      "        [-0.8120,  1.6090, -1.4952, -1.6685, -1.3468, -1.5940, -0.0069, -0.5587],\n",
      "        [-2.2360,  1.3833,  1.0433,  1.1669, -0.3820,  0.7385, -0.5996,  1.3503],\n",
      "        [-0.0796, -1.4015,  0.8312,  0.3304,  0.0167, -3.0018,  0.7606,  0.4953],\n",
      "        [-2.6711,  0.2311, -0.6963, -1.4831,  0.7733,  0.0064, -0.9866,  0.8588]])\n",
      "------------------\n",
      "Query :\t\n",
      "tensor([[    -0.7015,      0.8426,     -0.9616,     -1.8412,      1.0544,\n",
      "              1.5917,      1.2750,     -1.5763],\n",
      "        [     0.3223,      0.4414,     -0.1807,      1.3214,     -0.4039,\n",
      "             -1.1014,     -1.4851,      0.3144],\n",
      "        [     0.9922,      0.1144,      0.8940,      0.0193,     -0.1557,\n",
      "              0.1943,      0.8272,     -0.8803],\n",
      "        [    -0.1603,      1.1792,     -0.2884,     -0.5618,     -0.9560,\n",
      "             -2.4665,     -0.8574,     -0.1946],\n",
      "        [     0.5954,     -1.7543,      1.4713,     -0.2312,      0.0008,\n",
      "              1.2053,      0.5036,      0.2003],\n",
      "        [    -0.1054,     -0.9843,     -0.5703,      0.1923,      0.8084,\n",
      "             -0.0535,     -0.2942,     -0.4969],\n",
      "        [     0.8486,     -1.4074,     -1.0977,      0.3906,      0.9012,\n",
      "             -0.4514,      1.1988,     -1.0205],\n",
      "        [     1.2893,      0.9633,      0.9715,     -0.1861,      1.7658,\n",
      "              0.5938,     -1.0949,     -2.2097]])\n",
      "------------------\n",
      "Prod before softmax :\t\n",
      "tensor([[-3.7953,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 3.2707,  2.8977,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 1.6642,  0.6979,  4.3613,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 4.4848, -3.4059, -2.7415,  0.4964,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-1.3863, -0.5144,  6.0676, -0.0306,  1.3041,    -inf,    -inf,    -inf],\n",
      "        [ 2.6311,  0.6953, -1.5092, -2.2051, -2.7242, -3.2152,    -inf,    -inf],\n",
      "        [ 5.7814,  0.3336,  0.4243, -2.0839, -3.9819, -9.9135,  1.0640,    -inf],\n",
      "        [ 1.4080,  8.0757,  1.3217,  2.4472, -2.4048,  3.3891, -1.5383, -0.9095]])\n",
      "------------------\n",
      "Prod after softmax :\t\n",
      "tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "             0.0000,     0.0000],\n",
      "        [    0.5922,     0.4078,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "             0.0000,     0.0000],\n",
      "        [    0.0617,     0.0235,     0.9149,     0.0000,     0.0000,     0.0000,\n",
      "             0.0000,     0.0000],\n",
      "        [    0.9807,     0.0004,     0.0007,     0.0182,     0.0000,     0.0000,\n",
      "             0.0000,     0.0000],\n",
      "        [    0.0006,     0.0014,     0.9874,     0.0022,     0.0084,     0.0000,\n",
      "             0.0000,     0.0000],\n",
      "        [    0.8505,     0.1227,     0.0135,     0.0068,     0.0040,     0.0025,\n",
      "             0.0000,     0.0000],\n",
      "        [    0.9819,     0.0042,     0.0046,     0.0004,     0.0001,     0.0000,\n",
      "             0.0088,     0.0000],\n",
      "        [    0.0013,     0.9848,     0.0011,     0.0035,     0.0000,     0.0091,\n",
      "             0.0001,     0.0001]])\n"
     ]
    }
   ],
   "source": [
    "## For reproducibility ##\n",
    "torch.manual_seed(97)\n",
    "\n",
    "## Creating the mask ##\n",
    "\n",
    "query = torch.randn(8, 8)\n",
    "key = torch.randn(8, 8)\n",
    "\n",
    "print(f\"Key :\\t\\n{key}\")\n",
    "print(\"------------------\")\n",
    "print(f\"Query :\\t\\n{query}\")\n",
    "print(\"------------------\")\n",
    "\n",
    "prod = torch.tril(query @ key)\n",
    "prod[prod == 0] = float(\"-inf\")\n",
    "\n",
    "print(f\"Prod before softmax :\\t\\n{prod}\")\n",
    "print(\"------------------\")\n",
    "\n",
    "prod = torch.nn.functional.softmax(prod, dim=1)\n",
    "\n",
    "print(f\"Prod after softmax :\\t\\n{prod}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "140aafda",
   "metadata": {},
   "source": [
    "So we need to do something like this in our Transformer network. This will create the masks, which in the paper are known as \"weights\". Now, as we earlier saw, to do the entire attention block, we need to multiply this mask with the actual values. And funny enough we are going to do that exactly via another matrix called **Values**.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4129adde",
   "metadata": {},
   "source": [
    "Now I can say we are already ready to build our Transformer Decoder Block. (In this work we only need to do generation, hence, Transformer Decoder suffices our needs!!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7090de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building transformer decoder ##\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    \"\"\"The Transformer Decoder Block.\"\"\"\n",
    "\n",
    "    def __init__(self, sequence_length=8, d_model=512):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding #\n",
    "        self.embed = nn.Embedding(num_embeddings=len(vocab), embedding_dim=d_model)\n",
    "\n",
    "        # positional encoding network #\n",
    "        self.positional_embed = nn.Embedding(\n",
    "            num_embeddings=sequence_length, embedding_dim=d_model\n",
    "        )\n",
    "\n",
    "        # Key, query, value mlp #\n",
    "        self.keys_mlp = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.queries_mlp = nn.Linear(\n",
    "            in_features=d_model, out_features=d_model, bias=False\n",
    "        )\n",
    "        self.values_mlp = nn.Linear(\n",
    "            in_features=d_model, out_features=d_model, bias=False\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "\n",
    "        self.linear = nn.Linear(in_features=d_model, out_features=len(vocab))\n",
    "\n",
    "    def forward(self, x, device=device):\n",
    "\n",
    "        # Embedding input #\n",
    "        x = self.embed(x)\n",
    "        B, L, C = x.shape\n",
    "\n",
    "        # positional embedding #\n",
    "        pos = torch.arange(L, device=device).repeat(B, 1)\n",
    "        positional_embedding = self.positional_embed(pos)\n",
    "\n",
    "        # Adding input with positional embedding #\n",
    "        x = x + positional_embedding\n",
    "\n",
    "        # Mapping keys, queries and values #\n",
    "        k = self.keys_mlp(x)\n",
    "        q = self.queries_mlp(x)\n",
    "        v = self.values_mlp(x)\n",
    "\n",
    "        # Attention! Wohooo! #\n",
    "        out = torch.tril(k @ q.transpose(-1, -2)) / C**0.5\n",
    "        out = out.masked_fill(out == 0, float(\"-inf\"))\n",
    "        out = nn.functional.softmax(out, dim=-1)\n",
    "        out = out @ v\n",
    "\n",
    "        # Residual connection and layernorm #\n",
    "        x = self.layer_norm(out + x)\n",
    "\n",
    "        # Residual connection and final feedforward #\n",
    "        x = x + self.ffn(x)\n",
    "\n",
    "        # Final linear layer #\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7cd8c12",
   "metadata": {},
   "source": [
    "Boom!! Done... We just created our very simple Transformer network. This is very simple (but have all the core things) with a single head and only a single repeatation. I will derive the multi-head derivation in the next notebook. This notebook will grow very slowly and naively now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32fcc197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 4113])\n"
     ]
    }
   ],
   "source": [
    "## Testing ##\n",
    "\n",
    "test_decoder = TransformerDecoder()\n",
    "\n",
    "for batch_inp, batch_labels in poems_dl:\n",
    "    a = test_decoder(batch_inp, device=\"cpu\")\n",
    "    print(a.shape)\n",
    "    break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a171f3e",
   "metadata": {},
   "source": [
    "So, lets try training our model and see how it captures prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "152098ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating dataloader ##\n",
    "poems_dl = build_dl(poems_data)\n",
    "\n",
    "## Setting our model ##\n",
    "model = TransformerDecoder()\n",
    "model = model.to(device)\n",
    "\n",
    "## Loss function and optimizer ##\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e94bbdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:42<00:00, 106.02it/s, Loss=4.41]\n",
      "Epoch : 2 / 200 ::: 100%|███████████████████████████████████████████████| 4506/4506 [00:41<00:00, 107.83it/s, Loss=3.3]\n",
      "Epoch : 3 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:44<00:00, 101.50it/s, Loss=2.97]\n",
      "Epoch : 4 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:42<00:00, 105.26it/s, Loss=2.46]\n",
      "Epoch : 5 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:42<00:00, 106.47it/s, Loss=2.12]\n",
      "Epoch : 6 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:42<00:00, 106.32it/s, Loss=1.81]\n",
      "Epoch : 7 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:41<00:00, 107.98it/s, Loss=1.62]\n",
      "Epoch : 8 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:42<00:00, 105.56it/s, Loss=1.58]\n",
      "Epoch : 9 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:42<00:00, 105.20it/s, Loss=1.52]\n",
      "Epoch : 10 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:45<00:00, 98.55it/s, Loss=1.41]\n",
      "Epoch : 11 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:45<00:00, 98.96it/s, Loss=1.37]\n",
      "Epoch : 12 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:46<00:00, 96.62it/s, Loss=1.31]\n",
      "Epoch : 13 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:44<00:00, 100.44it/s, Loss=1.35]\n",
      "Epoch : 14 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:45<00:00, 98.88it/s, Loss=1.27]\n",
      "Epoch : 15 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:43<00:00, 102.56it/s, Loss=1.22]\n",
      "Epoch : 16 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:42<00:00, 105.32it/s, Loss=1.18]\n",
      "Epoch : 17 / 200 ::: 100%|███████████████████████████████████████████████| 4506/4506 [00:46<00:00, 96.81it/s, Loss=1.2]\n",
      "Epoch : 18 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:48<00:00, 93.51it/s, Loss=1.16]\n",
      "Epoch : 19 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:44<00:00, 100.25it/s, Loss=1.15]\n",
      "Epoch : 20 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:46<00:00, 95.90it/s, Loss=1.16]\n",
      "Epoch : 21 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:49<00:00, 90.99it/s, Loss=1.14]\n",
      "Epoch : 22 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:48<00:00, 93.29it/s, Loss=1.13]\n",
      "Epoch : 23 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:45<00:00, 99.77it/s, Loss=1.13]\n",
      "Epoch : 24 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:47<00:00, 94.88it/s, Loss=1.07]\n",
      "Epoch : 25 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:45<00:00, 98.41it/s, Loss=1.09]\n",
      "Epoch : 26 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:44<00:00, 100.59it/s, Loss=1.06]\n",
      "Epoch : 27 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:45<00:00, 100.12it/s, Loss=1.07]\n",
      "Epoch : 28 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:50<00:00, 89.83it/s, Loss=1.08]\n",
      "Epoch : 29 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:48<00:00, 93.44it/s, Loss=1.05]\n",
      "Epoch : 30 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:49<00:00, 90.19it/s, Loss=1.06]\n",
      "Epoch : 31 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:47<00:00, 95.37it/s, Loss=1.06]\n",
      "Epoch : 32 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:47<00:00, 93.91it/s, Loss=1.04]\n",
      "Epoch : 33 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:46<00:00, 96.60it/s, Loss=1.04]\n",
      "Epoch : 34 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:47<00:00, 94.19it/s, Loss=1.03]\n",
      "Epoch : 35 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:47<00:00, 95.78it/s, Loss=1.01]\n",
      "Epoch : 36 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:47<00:00, 95.23it/s, Loss=1.03]\n",
      "Epoch : 37 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:50<00:00, 89.01it/s, Loss=1.02]\n",
      "Epoch : 38 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:46<00:00, 95.99it/s, Loss=0.991]\n",
      "Epoch : 39 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:50<00:00, 88.79it/s, Loss=0.982]\n",
      "Epoch : 40 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:48<00:00, 92.07it/s, Loss=0.988]\n",
      "Epoch : 41 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:48<00:00, 93.35it/s, Loss=0.981]\n",
      "Epoch : 42 / 200 ::: 100%|█████████████████████████████████████████████████| 4506/4506 [00:48<00:00, 92.54it/s, Loss=1]\n",
      "Epoch : 43 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:53<00:00, 84.84it/s, Loss=1.01]\n",
      "Epoch : 44 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:56<00:00, 79.91it/s, Loss=1.02]\n",
      "Epoch : 45 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:49<00:00, 91.90it/s, Loss=0.989]\n",
      "Epoch : 46 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:48<00:00, 92.25it/s, Loss=0.999]\n",
      "Epoch : 47 / 200 ::: 100%|██████████████████████████████████████████████| 4506/4506 [00:52<00:00, 85.55it/s, Loss=1.01]\n",
      "Epoch : 48 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:50<00:00, 88.98it/s, Loss=0.969]\n",
      "Epoch : 49 / 200 ::: 100%|█████████████████████████████████████████████| 4506/4506 [00:48<00:00, 92.01it/s, Loss=0.964]\n",
      "Epoch : 50 / 200 ::: 100%|█████████████████████████████████████████████████| 4506/4506 [00:47<00:00, 95.02it/s, Loss=1]\n"
     ]
    }
   ],
   "source": [
    "## Training Loop ##\n",
    "\n",
    "batch_loss = []\n",
    "\n",
    "for i in range(50):\n",
    "    loop = tqdm(poems_dl)\n",
    "\n",
    "    minibatch_loss = []\n",
    "\n",
    "    for batch_inp, batch_labels in loop:\n",
    "        batch_inp = batch_inp.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        B, L = batch_inp.shape\n",
    "        pred = model(batch_inp)\n",
    "        pred = pred.view(B * L, -1)\n",
    "        batch_labels = batch_labels.view(B * L)\n",
    "        loss = loss_func(pred, batch_labels)\n",
    "        loop.set_description(f\"Epoch : {i + 1} / 200 ::\")\n",
    "        minibatch_loss.append(loss.item())\n",
    "        loop.set_postfix(Loss=sum(minibatch_loss) / len(minibatch_loss))\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    batch_loss.append(sum(minibatch_loss) / len(minibatch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fae53917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dare to tell,\n",
      "to be brim, and even above the grove, some waif\n",
      "\n",
      "except forget to go in fear perhaps.\n",
      "and, in the dust the grass was dry,\n",
      "\"how many are you, then,\" said i,\n",
      "and, that immortal sea\n",
      "a deep piece of some old running river\n",
      "had we can by were to we but who could pass by\n",
      "while the earth herself is adorning,\n",
      "nor know that she's there,\n",
      "it becomes a habit.\n",
      "is too much with us; late and soon,\n",
      "you must have seen me there,\n",
      "\"you say that two at conway dwell,\n",
      "of my mother's door,\n",
      "on the best way out as a look-off where we faced\n",
      "beside the wall stands bare,\n",
      "in this bush our sparrow built her nest,\n",
      "i have to).\n"
     ]
    }
   ],
   "source": [
    "## Generating ##\n",
    "\n",
    "model.eval()\n",
    "\n",
    "start_idx = torch.zeros((1, 1), device=\"cuda\").int()\n",
    "\n",
    "for i in range(20):\n",
    "    idx = start_idx\n",
    "    while True:\n",
    "        logits = model(idx[:, -8:])\n",
    "        logits = logits[:, -1, :]\n",
    "        prob = torch.nn.functional.softmax(logits, dim=1)\n",
    "        next_idx = torch.multinomial(prob, 1)\n",
    "        next_idx = next_idx.int()\n",
    "        if next_idx == 1:\n",
    "            print(\" \".join(show_data(idx[0, 1:].data, verbose=False)))\n",
    "            break\n",
    "        idx = torch.cat([idx, next_idx], dim=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5e25922",
   "metadata": {},
   "source": [
    "Amazing... This looks nice for a stop and jump back to the next notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Mar  2 2023, 03:18:16) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
